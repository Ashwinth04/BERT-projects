{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b0c5db-0f6d-418f-bc39-cd45947c900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "124c426f-a4c6-418c-a9ca-2815bca1b16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dr.G.Mahadevan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset, load_metric\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b9fb4ad-a309-442c-813a-c19db02335c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70a37dc9-4b92-476f-a0c6-b72eb51efbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"google/pegasus-cnn_dailymail\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fb6d097-aa15-4e66-889e-050fe4b656ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74965be3-81a7-4e6d-9841-933ab3266e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset samsum (C:/Users/Dr.G.Mahadevan/.cache/huggingface/datasets/samsum/samsum/0.0.0/f1d7c6b7353e6de335d444e424dc002ef70d1277109031327bc9cc6af5d3d46e)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.62it/s]\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"samsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3df17a5d-fa4c-4f50-baab-c9eb8016a2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 14732\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 819\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 818\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "305c08da-e625-415a-8370-d2bc1626b977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14732, 819, 818)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['train']), len(data['test']), len(data['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4b1f9a4-b017-403e-8889-18b425517387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'dialogue', 'summary']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db0c0585-5996-48d8-acd0-38d1d641ec2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue\n",
      "Eric: MACHINE!\n",
      "Rob: That's so gr8!\n",
      "Eric: I know! And shows how Americans see Russian ;)\n",
      "Rob: And it's really funny!\n",
      "Eric: I know! I especially like the train part!\n",
      "Rob: Hahaha! No one talks to the machine like that!\n",
      "Eric: Is this his only stand-up?\n",
      "Rob: Idk. I'll check.\n",
      "Eric: Sure.\n",
      "Rob: Turns out no! There are some of his stand-ups on youtube.\n",
      "Eric: Gr8! I'll watch them now!\n",
      "Rob: Me too!\n",
      "Eric: MACHINE!\n",
      "Rob: MACHINE!\n",
      "Eric: TTYL?\n",
      "Rob: Sure :)\n",
      "Summary\n",
      "Eric and Rob are going to watch a stand-up on youtube.\n"
     ]
    }
   ],
   "source": [
    "print(\"Dialogue\")\n",
    "print(data['test'][1]['dialogue'])\n",
    "print(\"Summary\")\n",
    "print(data['test'][1]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc512fb3-98e8-41f8-8897-80d26876af2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be shy, he's very nice\n",
      "Hannah: If you say so..\n",
      "Hannah: I'd rather you texted him\n",
      "Amanda: Just text him ðŸ™‚\n",
      "Hannah: Urgh.. Alright\n",
      "Hannah: Bye\n",
      "Amanda: Bye bye\n",
      "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n"
     ]
    }
   ],
   "source": [
    "dialogue = data['test'][0]['dialogue']\n",
    "summary = data['test'][0]['summary']\n",
    "print(dialogue)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63997a0e-6848-4ba0-a2c7-ab96ae8473e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline('summarization', model = model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1926e80b-cd0f-4724-85c8-fd97fd4469bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96091816-2b85-4459-a981-5ab9217d61a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"Amanda: Ask Larry Amanda: He called her last time we were at the park together .<n>Hannah: I'd rather you texted him .<n>Amanda: Just text him .\"}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4261d7e-0143-4dfd-8401-814c53ffbf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(list_of_elements, batch_size):\n",
    "    for i in range(0,len(list_of_elements),batch_size):\n",
    "        yield list_of_elements[i:i+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c9d11cc-1241-41e2-bbcc-0f2e09560220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metric_on_test(dataset,metric,model,tokenizer,batch_size = 16, column_text = \"article\", column_summary = \"highlights\"):\n",
    "    article_batches = list(generate_batches(dataset[column_text],batch_size))\n",
    "    target_batches = list(generate_batches(dataset[column_summary],batch_size))\n",
    "    \n",
    "    for article_batch, target_batch in tqdm(zip(article_batches,target_batches), total = len(article_batches)):\n",
    "        inputs = tokenizer(article_batch,max_length = 1024, truncation = True, padding = \"max_length\", return_tensors = 'pt')\n",
    "        summaries = model.generate(input_ids = inputs[\"input_ids\"], attention_mask = inputs[\"attention_mask\"], length_penalty = 0.8, num_beams = 8,max_length = 128)\n",
    "        \n",
    "        decoded_summaries = [tokenizer.decode(s,skip_special_tokens = True, clean_up_tokenization_spaces = True) for s in summaries]\n",
    "        decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n",
    "        metric.add_batch(predictions = decoded_summaries, references = target_batch)\n",
    "        \n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04363b3f-fad3-47c3-a992-93a3c8c323c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dr.G.Mahadevan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "  2%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                                                                                                        | 5/205 [1:28:40<58:45:11, 1057.56s/it]"
     ]
    }
   ],
   "source": [
    "rouge_metric = load_metric(\"rouge\")\n",
    "score = calculate_metric_on_test(data['test'],rouge_metric,model_pegasus,tokenizer,column_text = 'dialogue',column_summary = 'summary',batch_size = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d2279e-f4d4-4966-bc4a-399ff1370c54",
   "metadata": {},
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imageclassification",
   "language": "python",
   "name": "imageclassification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
